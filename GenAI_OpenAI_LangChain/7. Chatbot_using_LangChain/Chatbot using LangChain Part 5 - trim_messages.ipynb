{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a709de-28a1-4a0e-b9e0-459021983f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import trim_messages, AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6073190-e58d-4a08-8838-72cdfa9e0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ab973-7656-4e68-854d-522af451fecb",
   "metadata": {},
   "source": [
    "## trim_message\n",
    "\n",
    "Reference: https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.trim_messages.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99816f88-28d6-4408-8e1e-c7cbd0c4a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Hi my name is Yash\"),\n",
    "    AIMessage(\"Hi Yash, how can I help?\"),\n",
    "    HumanMessage(\"I just want to know my name\"),\n",
    "    AIMessage(\"It's Yash, please let me know if you need anything else.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f765d69-255a-42d8-8c02-8e45355f1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\",\n",
    "    token_counter=chat,\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    # start_on=\"human\" makes sure we produce a valid chat history\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe454325-ced9-46f4-97a4-a3af050e1636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_num_tokens_from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a642980b-4bc6-4f66-94c8-eb1e38bf5125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I just want to know my name', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"It's Yash, please let me know if you need anything else.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd7ac1c-cc50-4ef6-8f6e-90b1bdd6f42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625c9738-e60d-42ce-aed9-95ed6a5eb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8673226f-b371-49dd-8588-c3f228a55764",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a savage assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history_messages\"),\n",
    "        (\"human\", \"{input_user_message}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84941f7c-004b-4cbc-a6e3-fb65493027c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabb8a4f-f502-4057-a7c0-4395647a0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=40,\n",
    "    strategy=\"last\",\n",
    "    token_counter=chat,\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    # start_on=\"human\" makes sure we produce a valid chat history\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bf24e-f8d5-4c47-ae47-8f634da345e9",
   "metadata": {},
   "source": [
    "## ChatMessageHistory Integration\n",
    "\n",
    "Different integrations can be used out of the box for ChatMessageHistory.\n",
    "\n",
    "Reference: https://python.langchain.com/v0.1/docs/integrations/memory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd693cd-fc46-4081-8f03-189815d9c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    else:\n",
    "        store[session_id].messages = trimmer.invoke(store[session_id].messages)\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38eefa96-15fe-4b14-a532-8332c0faf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input_user_message\",\n",
    "    history_messages_key=\"history_messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90941560-0829-4a83-b7aa-98f80a2dba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Yash! What’s up?\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input_user_message\": \"hi my name is Yash\"},\n",
    "    {\"configurable\": {\"session_id\": \"1234\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3e3c95-b359-4fdb-b4f5-48da6f2882a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi my name is Yash', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice to meet you, Yash! What’s up?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_obj = get_session_history(session_id=\"1234\")\n",
    "chat_history_obj.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa6f480-14d4-4815-a13f-25cb9c869c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cool! Are they the kind of friends who help you move or the ones who just eat all your snacks?\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input_user_message\": \"I have 2 friends\"},\n",
    "    {\"configurable\": {\"session_id\": \"1234\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b555c4d7-1cba-4474-a7a8-c9760054a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I have 2 friends', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Cool! Are they the kind of friends who help you move or the ones who just eat all your snacks?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_obj = get_session_history(session_id=\"1234\")\n",
    "chat_history_obj.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35c30ed4-0462-4e7e-b380-d17ac4d6057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don’t know your name, but if you tell me, I’ll use it! Or I can just call you \"Friend\"—it has a nice ring to it.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input_user_message\": \"whats my name\"},\n",
    "    {\"configurable\": {\"session_id\": \"1234\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8e24c-103f-46c2-a68d-52db3ac3d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
