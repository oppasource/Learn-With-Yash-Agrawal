{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7472be32-d581-4063-8d1b-9faad0d2243d",
   "metadata": {},
   "source": [
    "# Running Llama-2-7b model locally\n",
    "\n",
    "Notebook demonstrates how one can run the model to get sentence completions and some sample prompts to try and get solutions to problems right out of the box.\n",
    "\n",
    "Note that it might not work at all if system does not have GPU (might work if there is enough CPU and RAM though).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eca9089-7852-4291-830a-714ba8fe9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e8ee81-55d7-4142-ae58-6a4ae17727ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fa7974e1e848f7acfd2bbc798db423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    cache_dir=\"/data/yash/base_models\",\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", cache_dir=\"/data/yash/base_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4997b3f0-47ba-41b4-9f5a-9d6c5b1d5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"She is\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c6d095-c835-4c9b-996a-5e9566f05e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1, 2296,  338]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6624d16-797c-4bb4-a89a-8fe120b2af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3f27b9-5dc5-4bab-82c6-b11601e15762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  2296,   338,   263,  7826,   411,   263, 12561, 29889,  2296,\n",
       "         10753,   304,   367]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdb7cf9-a953-46a8-b847-fcbda018d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9aee6fe-3ff6-49f4-a812-907235f4f572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She is a girl with a dream. She wants to be'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ba8f0e-dac5-4618-b426-3ed0cfcf6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf1de7c1-e184-49e1-a5da-7b5878ca65cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She is a 2016 graduate of the University of North Carolina at Chapel Hill, where she majored in English and minored in Creative Writing. She is currently a graduate student at the University of North Carolina at Chapel Hill,'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"She is\"\n",
    "get_llama2_reponse(prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5105ca07-d87e-4337-bdad-05c8814a9e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q:what is the capital of India? A:New Delhi. Q:what is the capital of India? A:New Delhi. Q:what is the capital of India? A:New Delhi. Q:what is the capital of India? A:New Delhi. Q'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Q:what is the capital of India? A:\"\n",
    "get_llama2_reponse(prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36aa4d79-9bef-456d-92ee-62f31dbbd748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"translation of sentence 'i want to eat' in hindi is 'मैं खाना चाहता हूं'\\nI want to eat.\\nमैं खाना चाहता हूं\\nI want to eat\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"translation of sentence 'i want to eat' in hindi is\"\n",
    "get_llama2_reponse(prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73b40d8c-f60d-4d9f-abe0-d9b03969d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"translation of sentence 'i want to eat' in french is 'je veux manger'\\nI want to eat.\\nI want to eat. I want to eat.\\nI want to eat. I want to eat. I want to eat.\\nI want to eat. I want to eat\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"translation of sentence 'i want to eat' in french is\"\n",
    "get_llama2_reponse(prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ca5e1e-6704-4523-ba47-cf2a2ddd364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python code to loop from 1 to 10 and print the numbers is:\n",
      "\n",
      "\\begin{code}\n",
      "for i in range(1, 11):\n",
      "    print(i)\n",
      "\\end{code}\n",
      "\n",
      "I want to write a code that will loop from 1 to 100\n"
     ]
    }
   ],
   "source": [
    "prompt='''python code to loop from 1 to 10 and print the numbers is:'''\n",
    "print(get_llama2_reponse(prompt, max_new_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf0c28-8508-498b-b1db-4ded25f410d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e55da-0ac9-4835-b420-5c181f2c2a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b88d90-ffc8-4e7b-998d-0c524a24baca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e99fc6-59a2-4248-a863-4523bde6460c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f048eb6-94bc-4e56-880e-9ccab3ea80a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
