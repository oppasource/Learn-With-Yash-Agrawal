{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac52e6e9-cae3-419e-a71e-6fa40c69bb1a",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "We will look at how to extract information from an interaction between Customer and an Agent. This might be useful in build a call center analysis dashboard kind of applicaiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f42bc27-cc75-4a07-a56d-7d6d9fd4c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/conda_env/yash/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b391a85-a328-447c-8c38-b088ed6a9c8d",
   "metadata": {},
   "source": [
    "# Loading and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0f324f-bd3b-4177-9e32-13e63566d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"jonathansuru/customer_service_information_extraction\", cache_dir = \"/data/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ae433f-0483-4ad2-bff5-1a8bcfa59d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'completion'],\n",
       "        num_rows: 190\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6452b9-b4df-430d-a34a-8b85d657667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please extract the customer specifications from the conversation below:\n",
      "\n",
      "###\n",
      "\n",
      "Agent: Hello, thank you for calling [Company Name]. How may I help you today?\n",
      "Customer: I'm calling to complain about a product that I purchased.\n",
      "Agent: I understand. Can you please tell me what product you're referring to?\n",
      "Customer: I purchased a [Product Name] from your website on August 10th. It arrived on August 15th, but it was damaged.\n",
      "Agent: I'm sorry to hear that. I'll be happy to help you with this. Can you send me a picture of the damaged product?\n",
      "Customer: Sure.\n",
      "...\n",
      "Agent: I've received the picture of the damaged product. I'm going to issue you a refund for the product. I'm also going to send you a replacement product.\n",
      "Customer: Thank you for your help.\n",
      "The extract is as follows:\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b22ff1-f465-4f72-a7aa-860c45abc455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"product name\": \"product name\",\n",
      "  \"issue\": \"damaged product\"\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['completion'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aacc3b-8dba-4f00-8f43-842d050f5814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da631e67-0505-4fc3-82b2-1ee7c720b0fe",
   "metadata": {},
   "source": [
    "## Zero Shot Setting (with base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c10b0fa-66a2-4345-bc16-1ad0fe5b0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    cache_dir=\"/data/base_models/\",\n",
    "    device_map='cuda:2',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", cache_dir=\"/data/base_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b54d6f-bf16-41f9-bc49-8db4bad1dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b12b8b-df68-4ec9-bf80-a99984be576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please extract the customer specifications from the conversation below:\n",
      "\n",
      "###\n",
      "\n",
      "Agent: Hello, thank you for calling [Company Name]. How may I help you today?\n",
      "Customer: I'm calling to complain about a product that I purchased.\n",
      "Agent: I understand. Can you please tell me what product you're referring to?\n",
      "Customer: I purchased a [Product Name] from your website on August 10th. It arrived on August 15th, but it was damaged.\n",
      "Agent: I'm sorry to hear that. I'll be happy to help you with this. Can you send me a picture of the damaged product?\n",
      "Customer: Sure.\n",
      "...\n",
      "Agent: I've received the picture of the damaged product. I'm going to issue you a refund for the product. I'm also going to send you a replacement product.\n",
      "Customer: Thank you for your help.\n",
      "The extract is as follows:\n",
      "\n",
      "###\n",
      "\n",
      "Agent: Hello, thank you for calling [Company Name]. How may I help you today?\n",
      "Customer: I'm calling to complain about a product that I purchased.\n",
      "Agent: I understand. Can you\n"
     ]
    }
   ],
   "source": [
    "prompt = data['train']['prompt'][0]\n",
    "print(get_llama2_reponse(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8621558-900e-42f1-95cd-29999476b3da",
   "metadata": {},
   "source": [
    "## Zero Shot Setting (with chat finetuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8ab6cc-a424-4342-9b89-45813654fa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    cache_dir=\"/data/base_models/\",\n",
    "    device_map='cuda:2',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/data/base_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30421f6a-1b1f-4944-86e1-4f1121477193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please extract the customer specifications from the conversation below:\n",
      "\n",
      "###\n",
      "\n",
      "Agent: Hello, thank you for calling [Company Name]. How may I help you today?\n",
      "Customer: I'm calling to complain about a product that I purchased.\n",
      "Agent: I understand. Can you please tell me what product you're referring to?\n",
      "Customer: I purchased a [Product Name] from your website on August 10th. It arrived on August 15th, but it was damaged.\n",
      "Agent: I'm sorry to hear that. I'll be happy to help you with this. Can you send me a picture of the damaged product?\n",
      "Customer: Sure.\n",
      "...\n",
      "Agent: I've received the picture of the damaged product. I'm going to issue you a refund for the product. I'm also going to send you a replacement product.\n",
      "Customer: Thank you for your help.\n",
      "The extract is as follows:\n",
      "\n",
      "* Product: [Product Name]\n",
      "* Date of purchase: August 10th\n",
      "* Date of delivery: August 15th\n",
      "* Damage: Damaged\n",
      "* Action taken by agent: Issued a refund\n"
     ]
    }
   ],
   "source": [
    "prompt = data['train']['prompt'][0]\n",
    "print(get_llama2_reponse(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9955a17-fea3-499b-8826-94625c6ed221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c771df1f-d8f5-4cd2-ac21-4a3d3d53afe2",
   "metadata": {},
   "source": [
    "The chat finetuned model does seem to give good results without any kind of training. We can do a bit of prompt engineering and improve the reuslts. Lets assume we tried all techniques but we still dont get desired output (that exact attributes and values that we want in desired format). We will go for fine-tuning Llama-2 model by ourselves using the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a224c79-122f-4fc7-970b-613b96fd729e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1492b-dbeb-460b-80b4-51d1b1bb5472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
